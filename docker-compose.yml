x-timezone: &timezone
  environment:
    TZ: Europe/London

x-user: &user
  user: root

services:

  devops_portainer:
    <<: [ *timezone ]
    image: portainer/portainer-ce:latest
    container_name: devops_portainer
    ports:
      - 9443:9443
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /root/volumes/devops/portainer:/data
    restart: unless-stopped

  monitoring_dozzle:
    <<: [ *timezone ]
    image: amir20/dozzle:latest
    container_name: monitoring_dozzle
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /root/volumes/monitoring/dozzle:/data
    ports:
      - 8050:8080
    restart: unless-stopped

  # AI Services
  ai_ollama:
    <<: [ *timezone, *user ]
    image: ollama/ollama:latest
    container_name: ai_ollama
    ports:
      - 5101:11434
    volumes:
      - /root/volumes/ai/ollama:/root/.ollama/models
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      OLLAMA_GPU_LAYERS: 999
      OLLAMA_NUM_GPU: 1
      OLLAMA_HOST: 0.0.0.0:11434
      OLLAMA_KEEP_ALIVE: 24h
    runtime: nvidia
    deploy:
      resources:
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA_GPU_1"
                value: 1
    restart: unless-stopped

  ai_comfyui:
    <<: [ *timezone, *user ]
    image: ghcr.io/takermanltd/takerman.comfyui:latest
    privileged: true
    container_name: ai_comfyui
    runtime: nvidia
    ports:
      - 5100:8188
    volumes:
      - /root/volumes/ai/comfyui/models:/opt/ComfyUI/models
      - /root/volumes/ai/comfyui/output:/opt/ComfyUI/output
      - /root/volumes/ai/comfyui/input:/opt/ComfyUI/input
      - /root/volumes/ai/comfyui/custom_nodes:/opt/ComfyUI/custom_nodes
      - /root/volumes/ai/comfyui/config:/opt/ComfyUI/config
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: all
      CUDA_VISIBLE_DEVICES: "0"
      OLLAMA_BASE_URL: http://ai_ollama:11434
    depends_on:
      - ai_ollama
    deploy:
      resources:
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA_GPU_2"
                value: 1
    restart: unless-stopped

  ai_openwebui:
    <<: [ *timezone, *user ]
    image: ghcr.io/open-webui/open-webui:latest
    container_name: ai_openwebui
    environment:
      CUDA_VISIBLE_DEVICES: "0"
    ports:
      - 5102:8080
    volumes:
      - /root/volumes/ai/openwebui:/app/backend/data
    deploy:
      resources:
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA_GPU_3"
                value: 1
    restart: unless-stopped

  ai_n8n:
    <<: [ *timezone, *user ]
    image: n8nio/n8n:latest
    container_name: ai_n8n
    ports:
      - 5103:5678
    environment:
      N8N_BASIC_AUTH_ACTIVE: "true"
      N8N_BASIC_AUTH_USER: takerman
      N8N_BASIC_AUTH_PASSWORD: Hakerman91!
      N8N_SECURE_COOKIE: "false"
      N8N_HOST: n8n-ai.takerman.net
      WEBHOOK_TUNNEL_URL: https://n8n-ai.takerman.net
      N8N_EDITOR_BASE_URL: https://n8n-ai.takerman.net
      WEBHOOK_URL: https://n8n-ai.takerman.net/
      N8N_USER_FOLDER: /home/node/.n8n
      DB_TYPE: sqlite
      DB_SQLITE_DATABASE: /home/node/.n8n/database.sqlite
    volumes:
      - /root/volumes/ai/n8n/data:/home/node/.n8n
      - /root/volumes/ai/n8n/local_files:/files
      - /root/volumes/ai/n8n/backups:/backups
    deploy:
      resources:
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA_GPU_4"
                value: 1
    restart: unless-stopped

  tool_jupyter:
    <<: [ *timezone, *user ]
    image: ghcr.io/takermanltd/takerman.jupyter:latest
    container_name: tool_jupyter
    runtime: nvidia
    ports:
      - 5104:8888
    volumes:
      - /root/volumes/ai/jupyter/notebooks:/workspace/notebooks
      - /root/volumes/ai/jupyter/data:/workspace/data
      - /root/volumes/ai/jupyter/models:/workspace/models
      - /root/volumes/ai/jupyter/config:/root/.jupyter
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: all
      CUDA_VISIBLE_DEVICES: 0
      JUPYTER_TOKEN: Hakerman91!
    deploy:
      resources:
        reservations:
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA_GPU_5"
                value: 1
    restart: unless-stopped

  # Monitoring Stack
  monitoring_prometheus:
    <<: [ *timezone ]
    image: prom/prometheus:latest
    container_name: monitoring_prometheus
    ports:
      - 9090:9090
    volumes:
      - /root/volumes/monitoring/prometheus/config:/etc/prometheus
      - /root/volumes/monitoring/prometheus/data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  monitoring_grafana:
    <<: [ *timezone ]
    image: grafana/grafana:latest
    container_name: monitoring_grafana
    ports:
      - 3001:3000
    volumes:
      - /root/volumes/monitoring/grafana/data:/var/lib/grafana
      - /root/volumes/monitoring/grafana/config:/etc/grafana
      - /root/volumes/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - /root/volumes/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      GF_SECURITY_ADMIN_USER: takerman
      GF_SECURITY_ADMIN_PASSWORD: Hakerman91!
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource,grafana-piechart-panel
      GF_SERVER_ROOT_URL: http://grafana.takerman.net
      GF_USERS_ALLOW_SIGN_UP: "false"
    depends_on:
      - monitoring_prometheus
    restart: unless-stopped

  monitoring_node_exporter:
    <<: [ *timezone ]
    image: prom/node-exporter:latest
    container_name: monitoring_node_exporter
    ports:
      - 9100:9100
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped

  monitoring_cadvisor:
    <<: [ *timezone ]
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: monitoring_cadvisor
    ports:
      - 8080:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    restart: unless-stopped

volumes:
  jupyter_config:
    driver: local
